{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pdb\n",
    "import requests\n",
    "from collections import defaultdict\n",
    "import random \n",
    "import time\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from tqdm import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import wraps\n",
    "from time import time as _timenow \n",
    "from sys import stderr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load CIFAR-10 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cifar():\n",
    "    \n",
    "    trn_data, trn_labels, tst_data, tst_labels = [], [], [], []\n",
    "    def unpickle(file):\n",
    "        with open(file, 'rb') as fo:\n",
    "            data = pickle.load(fo, encoding ='latin1')\n",
    "        return data\n",
    "    \n",
    "    for i in trange(1):\n",
    "        batchName = './data/data_batch_{0}'.format(i + 1)\n",
    "        unpickled = unpickle(batchName)\n",
    "        trn_data.extend(unpickled['data'])\n",
    "        trn_labels.extend(unpickled['labels'])\n",
    "    unpickled = unpickle('./data/test_batch')\n",
    "    tst_data.extend(unpickled['data'])\n",
    "    tst_labels.extend(unpickled['labels'])\n",
    "    return trn_data, trn_labels, tst_data, tst_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_prep(train, test):\n",
    "    ''' pre-processes the given image\n",
    "        performs mean normalization and other such operations'''\n",
    "    scaler = preprocessing.StandardScaler().fit(train)\n",
    "    test_data = scaler.transform(test)\n",
    "    train_data = scaler.transform(train)\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    with open(file, 'rb') as f:\n",
    "        data = pickle.load(f, encoding='latin1')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality reduction using PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_dim(**kwargs):\n",
    "    ''' performs dimensionality reduction'''\n",
    "    if kwargs['method'] == 'pca':\n",
    "        pca = PCA(n_components = kwargs['numbercomponents'])\n",
    "        pca = pca.fit(kwargs['train'])\n",
    "        train_new = pca.transform(kwargs['train'])\n",
    "        test_new = pca.transform(kwargs['test'])\n",
    "        return train_new, test_new\n",
    "    elif kwargs['method'] == 'lda':\n",
    "        c = LinearDiscriminantAnalysis(numbercomponents = 600)\n",
    "        c = c.fit(kwargs['train'], kwargs['train_label'])\n",
    "        train_new = c.transform(kwargs['train'])\n",
    "        test_new = c.transform(kwargs['test'])\n",
    "        return train_new, test_new\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification using kernel SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_mlp(X, Y, hidden_layer1, hidden_layer2, hidden_layer3, i, **kwargs):\n",
    "    ''' trains a classifier by taking input features\n",
    "        and their respective targets and returns the trained model'''\n",
    "    c = MLPClassifier(hidden_layer_sizes = (hidden_layer1, hidden_layer2, hidden_layer3), max_iter = i)\n",
    "    c.fit(X, Y)\n",
    "    return c\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(target, predicted):\n",
    "    f1 = f1_score(target, predicted, average='micro')\n",
    "    acc = accuracy_score(target, predicted)\n",
    "    return f1, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(**kwargs):\n",
    "    '''takes test data and trained classifier model,\n",
    "    performs classification and prints accuracy and f1-score'''\n",
    "    if kwargs['method'] == 'MLP':\n",
    "        if kwargs['method'] == 'MLP':\n",
    "            mlp = kwargs['model']\n",
    "            X_test = kwargs['test']\n",
    "            o = mlp.predict(X_test)\n",
    "        return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_hidden_layers():\n",
    "    trn_data, trn_labels, tst_data, tst_labels = load_cifar()\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(trn_data, trn_labels, test_size = 0.20)  \n",
    "    acc = []\n",
    "    x_axis = []\n",
    "    \n",
    "    \n",
    "    trn_data, tst_data = image_prep(X_train, X_test)\n",
    "    trn_data, tst_data = reduce_dimensions(train = trn_data, test = tst_data, method = 'pca', numbercomponents = 90)\n",
    "    model = MLPClassifier(hidden_layer_sizes = (100), max_iter = 5000)  \n",
    "    model.fit(trn_data, Y_train)\n",
    "    output = test(test = tst_data, model = model, method = 'MLP')\n",
    "    f_score, accuracy = evaluate(Y_test, output)\n",
    "    print('Val - F1 score: {}\\n Accuracy: {}'.format(f_score, accuracy))\n",
    "    acc.append(accuracy)\n",
    "    x_axis.append(1)\n",
    "    \n",
    "    \n",
    "    trn_data, tst_data = image_prep(X_train, X_test)\n",
    "    trn_data, tst_data = reduce_dimensions(train = trn_data, test = tst_data, method = 'pca', numbercomponents = 90)\n",
    "    model = MLPClassifier(hidden_layer_sizes = (100, 100), max_iter = 5000)  \n",
    "    model.fit(trn_data, Y_train)\n",
    "    output = test(test = tst_data, model = model, method = 'MLP')\n",
    "    f_score, accuracy = evaluate(Y_test, output)\n",
    "    print('Val - F1 score: {}\\n Accuracy: {}'.format(f_score, accuracy))\n",
    "    acc.append(accuracy)\n",
    "    x_axis.append(2)\n",
    "    \n",
    "    \n",
    "    trn_data, tst_data = image_prep(X_train, X_test)\n",
    "    trn_data, tst_data = reduce_dimensions(train = trn_data, test = tst_data, method = 'pca', numbercomponents = 90)\n",
    "    model = MLPClassifier(hidden_layer_sizes=(100, 100, 100), max_iter = 5000)  \n",
    "    model.fit(trn_data, Y_train)\n",
    "    output = test(test = tst_data, model = model, method = 'MLP')\n",
    "    f_score, accuracy = evaluate(Y_test, output)\n",
    "    print('Val - F1 score: {}\\n Accuracy: {}'.format(f_score, accuracy))\n",
    "    acc.append(accuracy)\n",
    "    x_axis.append(3)\n",
    "    \n",
    "    \n",
    "    trn_data, tst_data = image_prep(X_train, X_test)\n",
    "    trn_data, tst_data = reduce_dimensions(train = trn_data, test = tst_data, method = 'pca', numbercomponents = 90)\n",
    "    model = MLPClassifier(hidden_layer_sizes=(100, 100, 100, 100), max_iter = 5000)  \n",
    "    model.fit(trn_data, Y_train)\n",
    "    output = test(test = tst_data, model = model, method = 'MLP')\n",
    "    f_score, accuracy = evaluate(Y_test, output)\n",
    "    print('Val - F1 score: {}\\n Accuracy: {}'.format(f_score, accuracy))\n",
    "    acc.append(accuracy)\n",
    "    x_axis.append(4)\n",
    "    \n",
    "    trn_data, tst_data = image_prep(X_train, X_test)\n",
    "    trn_data, tst_data = reduce_dimensions(train = trn_data, test = tst_data, method = 'pca', numbercomponents = 90)\n",
    "    model = MLPClassifier(hidden_layer_sizes=(100, 100, 100, 100, 100), max_iter = 5000)  \n",
    "    model.fit(trn_data, Y_train)\n",
    "    output = test(test = tst_data, model = model, method = 'MLP')\n",
    "    f_score, accuracy = evaluate(Y_test, output)\n",
    "    print('Val - F1 score: {}\\n Accuracy: {}'.format(f_score, accuracy))\n",
    "    acc.append(accuracy)\n",
    "    x_axis.append(5)\n",
    "    \n",
    "    plt.plot(xaxis, acc)\n",
    "    plt.xlabel('No. of components for PCA')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.show()\n",
    "    \n",
    "    return acc_arr, x_axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_pca_components():\n",
    "    trn_data, trn_labels, tst_data, tst_labels = load_cifar()\n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(trn_data, trn_labels,test_size = 0.20) \n",
    "    acc = []\n",
    "    xaxis = []\n",
    "    i = 50\n",
    "    while i <= 150:\n",
    "        trn_data, tst_data = image_prep(X_train, X_test)\n",
    "        trn_data, tst_data = reduce_dim(train = trn_data, test = tst_data, method ='pca', numbercomponents = i)\n",
    "        model = classify_mlp(trn_data, Y_train, 300, 300, 300, 5000, method = 'MLP')\n",
    "        output = test(test = tst_data, model = model, method ='MLP')\n",
    "        f_score, accuracy = evaluate(Y_test, output)\n",
    "        print('Val - F1 score: {}\\n Accuracy: {}'.format(f_score, accuracy))\n",
    "        acc.append(accuracy)\n",
    "        xaxis.append(i)\n",
    "        i += 10\n",
    "        \n",
    "    plt.plot(xaxis, acc)\n",
    "    plt.xlabel('No. of components for PCA')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.show()\n",
    "    return acc, xaxis\n",
    "    \n",
    "    ''' perform dimesioality reduction/feature extraction and classify the features into one of 10 classses\n",
    "        print accuracy and f1-score.\n",
    "        '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_no_iter():\n",
    "    i = 1\n",
    "    acc= []\n",
    "    x_axis = []\n",
    "    while(i < 6):\n",
    "        trn_data, trn_labels, tst_data, tst_labels = load_cifar()\n",
    "        X_train, X_test, y_train, y_test = train_test_split(trn_data, trn_labels, test_size = 0.20)  \n",
    "        trn_data, tst_data = image_prep(X_train, X_test)\n",
    "        trn_data, tst_data = reduce_dim(train = trn_data, test = tst_data, method ='pca', numbercomponents = 100)\n",
    "        model = classify_mlp(trn_data, y_train, 200, 200, 200, i*1000, method = 'MLP')\n",
    "        output = test(test = tst_data, model= model, method = 'MLP')\n",
    "        f_score, accuracy = evaluate(y_test, output)\n",
    "        print('Val - F1 score: {}\\n Accuracy: {}'.format(f_score, accuracy))\n",
    "        \n",
    "        acc.append(accuracy)\n",
    "        x_axis.append(i*1000)\n",
    "        i +=1\n",
    "    plt.plot(x,acc)\n",
    "    plt.xlabel('No. of max iterations') \n",
    "    plt.ylabel('Accuracy') \n",
    "    plt.show()\n",
    "    return acc_arr, x_axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# varying number of nodes in each hidden layer 1000 to 4000\n",
    "\n",
    "def number_nodes():\n",
    "    i = 1\n",
    "    acc = []\n",
    "    x_axis = []\n",
    "    while(i<5):\n",
    "        trn_data, trn_labels, tst_data, tst_labels = load_cifar()\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(trn_data, trn_labels, test_size = 0.20)  \n",
    "        trn_data, tst_data = image_prep(X_train, X_test)\n",
    "        trn_data, tst_data = reduce_dim(train = trn_data, test = tst_data, method = 'pca', no_of_comp = 90)\n",
    "        model = classify_mlp(trn_data, Y_train, 1000*i, 1000*i, 1000*i, 5000, method = 'MLP')\n",
    "        output = test(test = tst_data, model= model, method='MLP')\n",
    "        f_score, accuracy = evaluate(Y_test, output)\n",
    "        print('Val - F1 score: {}\\n Accuracy: {}'.format(f_score, accuracy))\n",
    "        acc.append(accuracy)\n",
    "        x_axis.append(i*1000)\n",
    "        i +=1\n",
    "    plt.plot(x,acc)\n",
    "    plt.xlabel('No. nodes in a hidden layer') \n",
    "    plt.ylabel('Accuracy') \n",
    "    plt.show()\n",
    "    return acc_arr, x_axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_mlp_pca():\n",
    "    trn_data, trn_labels, tst_data, tst_labels = load_cifar()\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(trn_data, trn_labels, test_size = 0.20)\n",
    "    trn_data, tst_data = image_prep(X_train, X_test)\n",
    "    trn_data, tst_data = reduce_dim(train = trn_data, test = tst_data, method = 'pca', numbercomponents = 80)\n",
    "    model = classify_mlp(trn_data, Y_train, 2000, 2000, 2000, 5000, method = 'MLP')\n",
    "    output = test(test = tst_data, model= model, method = 'MLP')\n",
    "    f_score, accuracy = evaluate(Y_test, output)\n",
    "    print('Val - F1 score: {}\\n Accuracy: {}'.format(f_score, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_mlp_lda():\n",
    "    trn_data, trn_labels, tst_data, tst_labels = load_cifar()\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(trn_data, trn_labels, test_size = 0.20)\n",
    "    trn_data, tst_data = image_prep(X_train, X_test)\n",
    "    trn_data, tst_data = reduce_dim(train = trn_data, test = tst_data, train_label = Y_train, method = 'lda')\n",
    "    model = classify_mlp(trn_data, Y_train, 2000, 2000, 2000, 5000, method = 'MLP')\n",
    "    output = test(test = tst_data, model= model, method = 'MLP')\n",
    "    f_score, accuracy = evaluate(Y_test, output)\n",
    "    print('Val - F1 score: {}\\n Accuracy: {}'.format(f_score, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_mlp_raw():\n",
    "    trn_data, trn_labels, tst_data, tst_labels = load_cifar()\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(trn_data, trn_labels, test_size = 0.20)\n",
    "    trn_data, tst_data = image_prep(X_train, X_test)\n",
    "#     trn_data, tst_data = reduce_dimensions(train = trn_data, test = tst_data, train_label = Y_train, method = 'lda')\n",
    "    model = classify_mlp(trn_data, Y_train, 2000, 2000, 2000, 5000, method = 'MLP')\n",
    "    output = test(test = tst_data, model= model, method = 'MLP')\n",
    "    f_score, accuracy = evaluate(Y_test, output)\n",
    "    print('Val - F1 score: {}\\n Accuracy: {}'.format(f_score, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  5.85it/s]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "#     find_pca_components()\n",
    "#     find_min_samples_split()\n",
    "#     find_n_estimators()\n",
    "#     final_pca()\n",
    "#     final_lda()\n",
    "#     find_pca_components_svm()\n",
    "    final_mlp_pca()\n",
    "    final_mlp_lda()\n",
    "    final_mlp_raw()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
